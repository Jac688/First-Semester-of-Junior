{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c875da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a12925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    buying  maint  doors persons lug_boot safety\n",
      "0      low  vhigh      3    more      med    med\n",
      "1    vhigh   high      2    more    small   high\n",
      "2    vhigh    med  5more       4      med   high\n",
      "3      med    med  5more       4    small    med\n",
      "4     high    med      4       4    small   high\n",
      "..     ...    ...    ...     ...      ...    ...\n",
      "474    low  vhigh      4       4      big   high\n",
      "475    med  vhigh      3    more      big   high\n",
      "476  vhigh    low      3       4      big   high\n",
      "477    med  vhigh      2       2      med    med\n",
      "478    med  vhigh      2       4      med    low\n",
      "\n",
      "[479 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "filename=\"./dataset/test.csv\"\n",
    "\n",
    "# import the test data \n",
    "from pandas import read_csv\n",
    "f=open(filename,encoding='UTF-8')\n",
    "test=read_csv(f)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "053ff7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     buying  maint  doors persons lug_boot safety evaluation\n",
      "0      high    low  5more       2      med    med      unacc\n",
      "1       med    low  5more       4    small    low      unacc\n",
      "2       med    med      4    more      med    low      unacc\n",
      "3       low    med      3    more      med    low      unacc\n",
      "4       low  vhigh      3    more      big    low      unacc\n",
      "...     ...    ...    ...     ...      ...    ...        ...\n",
      "1110    med  vhigh  5more    more    small    low      unacc\n",
      "1111  vhigh   high      4       4      big    med      unacc\n",
      "1112  vhigh   high      3    more      med    low      unacc\n",
      "1113    med    med      4       2      big    med      unacc\n",
      "1114    low    low  5more       4    small    low      unacc\n",
      "\n",
      "[1115 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "filename=\"./dataset/training.csv\"\n",
    "f=open(filename,encoding='UTF-8')\n",
    "training=read_csv(f)\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020e9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = training['evaluation'].values\n",
    "train_target[train_target=='unacc']=1\n",
    "train_target[train_target=='acc']=0\n",
    "\n",
    "train_attr = training.drop('evaluation', axis=1)\n",
    "train_input = pd.get_dummies(train_attr).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe4ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuro(train_input, test, train_target, apha, bias):\n",
    "    lst_res = []\n",
    "    weight = np.zeros(train_input.shape[1])\n",
    "#     print(weight*train_input[1])\n",
    "    for i in range(0, len(train_input)):\n",
    "        # The prediction result is determined by the activation function\n",
    "        O = activation((weight*train_input[i]).sum()-bias)\n",
    "        # Whether the weight is updated is determined by whether the predicted value is equal to the actual value\n",
    "        T = train_target[i]\n",
    "        # Each iteration it should update the weight by the function\n",
    "        # Whether the weight is updated is determined by whether the predicted value is equal to the actual value\n",
    "        weight = weight + apha*(T-O)*train_input[i]\n",
    "    for i in range(0, len(test)):\n",
    "        neuro_res = activation((weight*test[i]).sum()-bias)\n",
    "        lst_res.append(neuro_res)\n",
    "#     print(lst_res)\n",
    "    # the retrun data type is a series so that geting the score more easily\n",
    "    return pd.Series(lst_res)\n",
    "\n",
    "\n",
    "# activation fuction\n",
    "def activation(x):\n",
    "    if x >=0:\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "#     print(y)\n",
    "    return y\n",
    "\n",
    "# test should not call this function\n",
    "def scoreRes(ser_res, train_target):\n",
    "    ser_target = pd.Series(train_target)\n",
    "    train_res = pd.DataFrame([ser_res,ser_target]).T\n",
    "    train_res.columns = ['pred', 'actl']\n",
    "    train_res_des = train_res.value_counts()\n",
    "    # Get the four elements in the statistical table \n",
    "    TP = train_res_des[1][1]\n",
    "    FN = train_res_des[0][1]\n",
    "    FP = train_res_des[1][0]\n",
    "    TN = train_res_des[0][0]\n",
    "    \n",
    "    # case1: unacc is positive and acc is negative\n",
    "    # the calculation way of the precision, recall and f_score\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f_score = 2*precision*recall/(precision+recall)\n",
    "    accuracy = train_res[train_res['pred']==train_res['actl']].shape[0]/train_res.shape[0]\n",
    "    print(\"unacc is positive and acc is negative\")\n",
    "    print('precision: ' + str(precision) + ', recall: ' + str(recall) + ', f_score: ' + str(f_score))\n",
    "\n",
    "    # case2: acc is positive and unacc is negative\n",
    "    # the calculation way of the precision, recall and f_score\n",
    "    TP = train_res_des[0][0]\n",
    "    FN = train_res_des[1][0]\n",
    "    FP = train_res_des[0][1]\n",
    "    TN = train_res_des[1][1]\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f_score = 2*precision*recall/(precision+recall)\n",
    "    accuracy = train_res[train_res['pred']==train_res['actl']].shape[0]/train_res.shape[0]\n",
    "    print(\"acc is positive and unacc is negative\")\n",
    "    print('precision: ' + str(precision) + ', recall: ' + str(recall) + ', f_score: ' + str(f_score))\n",
    "    \n",
    "    return f_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160762db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unacc is positive and acc is negative\n",
      "precision: 0.957286432160804, recall: 0.900709219858156, f_score: 0.928136419001218\n",
      "acc is positive and unacc is negative\n",
      "precision: 0.7366771159874608, recall: 0.8736059479553904, f_score: 0.7993197278911565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7993197278911565"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = neuro(train_input, train_input, train_target, 1, 1)\n",
    "scoreRes(pred, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e49f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      unacc\n",
       "1      unacc\n",
       "2        acc\n",
       "3        acc\n",
       "4        acc\n",
       "       ...  \n",
       "474      acc\n",
       "475      acc\n",
       "476      acc\n",
       "477    unacc\n",
       "478    unacc\n",
       "Length: 479, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the test result\n",
    "test_attr = pd.get_dummies(test).values\n",
    "pred = neuro(train_input, test_attr, train_target, 1, 1)\n",
    "pred[pred==1] = 'unacc'\n",
    "pred[pred==0] = 'acc'\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47686c2d",
   "metadata": {},
   "source": [
    "# Modify the activation fuction and define the boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2432d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8621219887237315\n",
      "0.8618387262455058\n",
      "0.8615542974781266\n",
      "0.8614116434827408\n",
      "0.8611254517294786\n",
      "0.8608380755302639\n",
      "0.8602597402597404\n",
      "0.8602597402597403\n",
      "0.860114404576183\n",
      "0.8598228243877019\n",
      "0.8598228243877021\n",
      "0.8593831677992682\n",
      "0.859088528025144\n",
      "0.859822824387702\n",
      "0.859236002093145\n",
      "0.859383167799268\n",
      "0.8578975171685156\n",
      "0.857596611964002\n",
      "0.8569909622541202\n",
      "0.8577472236911687\n",
      "0.8589407446250654\n",
      "0.8589407446250655\n",
      "0.8577472236911687\n",
      "0.8556092324208265\n",
      "0.8586442459274829\n",
      "0.85529854760624\n",
      "0.8537248504622078\n",
      "0.8560727661851257\n",
      "0.8566862013851892\n",
      "0.8602597402597402\n",
      "0.8529250956807\n",
      "0.8586442459274829\n",
      "0.8557640750670242\n",
      "0.8581971534001055\n",
      "0.8560727661851258\n",
      "0.8571428571428572\n",
      "0.8571428571428572\n",
      "0.85529854760624\n",
      "0.8598228243877017\n",
      "0.8560727661851257\n",
      "0.8571428571428572\n",
      "0.8565333333333333\n",
      "0.8560727661851257\n",
      "0.8556092324208268\n",
      "0.8552985476062398\n",
      "0.8549865229110513\n",
      "0.8546731496488383\n",
      "0.8546731496488384\n",
      "0.8545159545700379\n",
      "0.8543584190579318\n",
      "0.8546731496488386\n",
      "0.8548300053966542\n",
      "0.8540423223005968\n",
      "0.8556092324208266\n",
      "0.854515954570038\n",
      "0.8554540569586244\n",
      "0.8542005420054202\n",
      "0.8540423223005968\n",
      "0.8534059945504087\n",
      "0.8548300053966541\n",
      "0.8540423223005968\n",
      "0.8552985476062399\n",
      "0.8543584190579318\n",
      "0.8529250956806999\n",
      "0.8559185859667916\n",
      "0.8521165475536008\n",
      "0.8503060656649973\n",
      "0.8527640941434045\n",
      "0.8538837588267247\n",
      "0.8580474934036939\n",
      "0.8487914558740867\n",
      "0.8560727661851257\n",
      "0.8524410312671421\n",
      "0.8546731496488383\n",
      "0.8529250956806999\n",
      "0.8549865229110513\n",
      "0.8540423223005968\n",
      "0.8522789676002196\n",
      "0.8589407446250654\n",
      "0.8538837588267245\n",
      "0.8527640941434045\n",
      "0.8526027397260274\n",
      "0.8526027397260273\n",
      "0.8526027397260274\n",
      "0.8524410312671421\n",
      "0.8522789676002197\n",
      "0.8517906336088154\n",
      "0.851627137341423\n",
      "0.8514632799558256\n",
      "0.851299060254284\n",
      "0.8517906336088155\n",
      "0.8519537699504678\n",
      "0.8512990602542841\n",
      "0.8526027397260273\n",
      "0.8521165475536008\n",
      "0.8538837588267246\n",
      "0.8524410312671421\n",
      "0.851299060254284\n",
      "0.8499721137757948\n",
      "0.8532460447354064\n",
      "0.8527640941434045\n",
      "0.8543584190579319\n",
      "0.8537248504622077\n",
      "0.851627137341423\n",
      "0.8548300053966541\n",
      "0.8498045784477946\n",
      "0.8489612577203818\n",
      "0.8509695290858725\n",
      "0.8530857454942655\n",
      "0.8571428571428572\n",
      "0.8460217515741272\n",
      "0.854830005396654\n",
      "0.8508042151968941\n",
      "0.8532460447354064\n",
      "0.8516271373414231\n",
      "0.8532460447354064\n",
      "0.8534059945504087\n",
      "0.8511344770337577\n",
      "0.8587926509186352\n",
      "0.8512990602542841\n",
      "0.8424135910954892\n",
      "0.8433313919627257\n",
      "0.8435136707388016\n",
      "0.8445984979780474\n",
      "0.8445984979780474\n",
      "0.8445984979780473\n",
      "0.8445984979780474\n",
      "0.8451352907311457\n",
      "0.8454910970706491\n",
      "0.8454910970706491\n",
      "0.8456683878370626\n",
      "0.8461978273299029\n",
      "0.8461978273299029\n",
      "0.8481084133258046\n",
      "0.8484507042253522\n",
      "0.8509695290858725\n",
      "0.8482797518330514\n",
      "0.8481084133258047\n",
      "0.847764572722128\n",
      "0.8482797518330513\n",
      "0.8486212718064152\n",
      "0.8529250956807\n",
      "0.8506385341476957\n",
      "0.847936687394008\n",
      "0.852441031267142\n",
      "0.8463735008566534\n",
      "0.8445984979780474\n",
      "0.8486212718064153\n",
      "0.8508042151968941\n",
      "0.8556092324208266\n",
      "0.8433313919627257\n",
      "0.8529250956806999\n",
      "0.8472458830210108\n",
      "0.8516271373414231\n",
      "0.8491306786315199\n",
      "0.8517906336088155\n",
      "0.8526027397260274\n",
      "0.8487914558740866\n",
      "0.8574456809750927\n",
      "0.849299719887955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8621219887237315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# data pre-processing\n",
    "train_target = training['evaluation'].values\n",
    "train_target[train_target=='unacc']=1\n",
    "train_target[train_target=='acc']=0\n",
    "\n",
    "train_attr = training.drop('evaluation', axis=1)\n",
    "train_input = pd.get_dummies(train_attr).values\n",
    "\n",
    "def neuro(train_input, test, train_target, apha, bias, boundary):\n",
    "    lst_res = []\n",
    "    weight = np.zeros(train_input.shape[1])\n",
    "#     print(weight*train_input[1])\n",
    "    for i in range(0, len(train_input)):\n",
    "        # Each iteration it should update the weight by the function\n",
    "        # Whether the weight is updated is determined by whether the predicted value is equal to the actual value\n",
    "        O = activation((weight*train_input[i]).sum()-bias)\n",
    "        T = train_target[i]\n",
    "        weight = weight + apha*(T-O)*train_input[i]\n",
    "#         Use the weights that you finally train to predict the outcome\n",
    "    for i in range(0, len(train_input)):\n",
    "        neuro_res = activation((weight*train_input[i]).sum()-bias)\n",
    "        lst_res.append(neuro_res)\n",
    "    return scoreRes(lst_res, train_target, boundary)\n",
    "\n",
    "\n",
    "# activation fuction\n",
    "# \n",
    "def activation(x):\n",
    "    y = 1/(1+np.e**(-x))\n",
    "#     print(y)\n",
    "    return y\n",
    "\n",
    "def scoreRes(lst_res, train_target, boundary):\n",
    "    ser_res = pd.Series(lst_res)\n",
    "    ser_unacc = ser_res[ser_res>boundary]\n",
    "\n",
    "    ser_unacc[:]= 1\n",
    "    ser_acc = ser_res[ser_res<=boundary]\n",
    "    ser_acc[:]= 0\n",
    "    ser_acc.index\n",
    "#     print(ser_acc)\n",
    "    # acc is positive and unacc is negative\n",
    "    # the calculation way of the precision, recall and f_score\n",
    "    ser_target = pd.Series(train_target)\n",
    "    target_pos = ser_target[ser_target==1]\n",
    "    target_neg = ser_target[ser_target==0]\n",
    "    train_TP = len(set(target_pos.index) & set(ser_unacc.index))\n",
    "    train_TN = len(set(target_pos.index) & set(ser_acc.index))\n",
    "    train_FP = len(set(target_neg.index) & set(ser_unacc.index))\n",
    "    train_FN = len(set(target_neg.index) & set(ser_acc.index))\n",
    "\n",
    "#     print(ser_acc)\n",
    "#     print(ser_unacc)\n",
    "    precision = train_TP / (train_TP+train_FP)\n",
    "    recall = train_TP / (train_TP+train_FN)\n",
    "    f_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(f_score)\n",
    "    return f_score\n",
    "    # \n",
    "a = np.arange(0.01, 1, 0.3)\n",
    "neuro1 = []\n",
    "for i in a:\n",
    "    for j in np.arange(1, 5, 0.1):\n",
    "        neuro1.append(neuro(train_input, test, train_target, j, 1, i))    \n",
    "x = np.array(neuro1).max()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cab29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a8188b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56b6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
