{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a40090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba2f8d",
   "metadata": {},
   "source": [
    "## 读取数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0043db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = pd.read_csv('./dataset-20211103/training.csv')\n",
    "test_d = pd.read_csv('./dataset-20211103/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe739d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint  doors persons lug_boot safety evaluation\n",
       "0   high    low  5more       2      med    med      unacc\n",
       "1    med    low  5more       4    small    low      unacc\n",
       "2    med    med      4    more      med    low      unacc\n",
       "3    low    med      3    more      med    low      unacc\n",
       "4    low  vhigh      3    more      big    low      unacc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_d.head()\n",
    "#test_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ba7ea",
   "metadata": {},
   "source": [
    "## 预处理， 简单的将其转为独热码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88d9cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=training_d['evaluation'].values\n",
    "labels[labels=='unacc']=0\n",
    "labels[labels=='acc']=1\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3df07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = training_d.drop('evaluation', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f7843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = pd.get_dummies(train_1).values\n",
    "input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14175bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = net(input_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "499f0ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epoch0,the loss is  1.2589640043678922\n",
      "num_epoch100,the loss is  0.9400895673391062\n",
      "num_epoch200,the loss is  0.7303994120762803\n",
      "num_epoch300,the loss is  0.7002096760945338\n",
      "num_epoch400,the loss is  0.6949726666187088\n",
      "num_epoch500,the loss is  0.6936780398470758\n",
      "num_epoch600,the loss is  0.693307825795077\n",
      "num_epoch700,the loss is  0.6931965382934345\n",
      "num_epoch800,the loss is  0.693162448385318\n",
      "num_epoch900,the loss is  0.6931519195918703\n"
     ]
    }
   ],
   "source": [
    "net_1.training(input_=input_,labels=labels,lr=0.0001,loss_function=cross_entropy_loss,epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d07eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of the perceptron\n",
    "#def data_iter(features, labels, batch_size):\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "def softmax(x):\n",
    "    '''soft max functiom'''\n",
    "    x=np.array(x,dtype=np.float64)\n",
    "    x_exp = np.exp(x)\n",
    "    partition = np.sum(x_exp,axis=1, keepdims=True)    \n",
    "    return x_exp/partition\n",
    "# def net(input_, weight, bias):\n",
    "#     '''model'''\n",
    "#     o = softmax(np.dot(input_, weight+bias))\n",
    "#     return o\n",
    "def cross_entropy_loss(y_hat,y):\n",
    "    '''cross entropy loss\n",
    "       y is the real label \n",
    "       y_hat is the predicting location in the index\n",
    "    '''\n",
    "    #only choose the correctly index to calculate the loss\n",
    "    #print(y.astype('int64'))\n",
    "    return -np.log(y_hat[range(len(y_hat)), y.astype('int64')])\n",
    "def gradient_for_cross_entropy_loss(y,y_hat):\n",
    "    return y_hat - y.reshape(len(y_hat),1)\n",
    "def back_propagation(weight, bias, X,gradient, lr):\n",
    "    '''objective function is the cross entropy loss\n",
    "        l(y,y_hat) = -log yi\n",
    "    '''\n",
    "    # the softmax back and loss back are together\n",
    "    gradient_out = gradient\n",
    "    #print(gradient_out.shape,X.shape,weight.shape)\n",
    "   # print(weight)\n",
    "    weight = weight- lr*(np.matmul(gradient_out.T, X)).T\n",
    "    #print(weight)\n",
    "    return weight, bias\n",
    "\n",
    "class net(object):\n",
    "    def __init__(self, input_size):\n",
    "        '''initialize'''\n",
    "        self.weight_matrix=np.random.normal(0,1,size=(input_size,2)) \n",
    "        self.bias = np.random.normal(0,1,size = (input_size,1))\n",
    "    def __repr__(self):\n",
    "        '''return the weight '''\n",
    "        return self.weight_matrix, self.bias\n",
    "    def forward(self,input_):\n",
    "        '''given the input matrix'''\n",
    "        o = softmax(np.matmul(input_,self.weight_matrix+self.bias))\n",
    "        return o\n",
    "    def backward(self, input_, output,y, lr=0.01):\n",
    "        return back_propagation(self.weight_matrix, self.bias,input_, gradient_for_cross_entropy_loss(y,output), lr)\n",
    "    \n",
    "    def training(self, input_, labels, lr, loss_function,epoch=10000):\n",
    "        for i in range(epoch):\n",
    "            o = self.forward(input_)\n",
    "            self.weight_matrix,self.bias = self.backward(input_, o, labels, lr)\n",
    "            #loss\n",
    "            loss=loss_function(o,labels).mean()\n",
    "            #print the loss \n",
    "            if i %100==0:\n",
    "                print(\"num_epoch\"+str(i)+\",the loss is \",loss)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "781490a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = net_1.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0d16796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-7.180259631939164, -6.325771041564379],\n",
       "        [-7.365685057483486, -6.511185728840833],\n",
       "        [-5.602342558566223, -4.747861615478976],\n",
       "        [-10.584154701953175, -9.729664547915988],\n",
       "        [-6.999344243793294, -7.054890679147975],\n",
       "        [-7.142490019384865, -7.1980519729411165],\n",
       "        [-5.911365006303656, -5.966909990252956],\n",
       "        [-10.287384061475056, -10.342933661032461],\n",
       "        [-7.4291087268628395, -7.5892243209715895],\n",
       "        [-7.79820275416524, -7.958319346983448],\n",
       "        [-6.457756820301302, -6.617871725953655],\n",
       "        [-6.63019929243558, -6.790308393883437],\n",
       "        [-19.060080211197015, -20.10702986094734],\n",
       "        [-3.0058802341569093, -4.052830061770716],\n",
       "        [-4.617340623397434, -5.664288207029492],\n",
       "        [-7.581218352941471, -6.9524053081899],\n",
       "        [-8.894580457198295, -8.265766015855705],\n",
       "        [-12.139434091875481, -11.510621023874585],\n",
       "        [-3.5505483779008347, -3.7712370578968346],\n",
       "        [-20.594927970290108, -20.815616880227896],\n",
       "        [-5.091124716646134, -5.311815214923009]], dtype=object),\n",
       " array([[-0.9582656 ],\n",
       "        [-0.32837178],\n",
       "        [ 2.57567735],\n",
       "        [-0.2686731 ],\n",
       "        [-1.5906137 ],\n",
       "        [-1.06187979],\n",
       "        [-0.18647312],\n",
       "        [ 2.66680341],\n",
       "        [ 1.26770704],\n",
       "        [-0.37690588],\n",
       "        [ 1.53108669],\n",
       "        [ 0.9564495 ],\n",
       "        [-2.0285557 ],\n",
       "        [-0.70178102],\n",
       "        [-0.47455204],\n",
       "        [-0.53105946],\n",
       "        [ 1.4482102 ],\n",
       "        [ 1.19459841],\n",
       "        [ 0.21914886],\n",
       "        [-0.75276907],\n",
       "        [-0.18428075]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30129f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
